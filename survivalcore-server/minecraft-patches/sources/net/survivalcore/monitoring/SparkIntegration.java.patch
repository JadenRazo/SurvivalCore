--- /dev/null
+++ b/net/survivalcore/monitoring/SparkIntegration.java
@@ -1,0 +_,136 @@
+package net.survivalcore.monitoring;
+
+import java.lang.reflect.Method;
+import java.util.concurrent.CompletableFuture;
+import java.util.logging.Level;
+import java.util.logging.Logger;
+import me.lucko.spark.api.Spark;
+import me.lucko.spark.api.SparkProvider;
+
+/**
+ * Integration with the Spark profiler for advanced performance diagnostics.
+ * Spark is bundled with Paper 1.21+ so it's always available.
+ *
+ * Uses reflection for profiler methods to handle API changes across versions.
+ */
+public final class SparkIntegration {
+
+    private static final Logger LOGGER = Logger.getLogger("SurvivalCore");
+    private static volatile Spark spark;
+    private static volatile boolean initialized = false;
+    private static volatile boolean available = false;
+
+    private SparkIntegration() {}
+
+    /**
+     * Initialize Spark integration.
+     * Called during server startup after Spark is loaded.
+     */
+    public static void init() {
+        if (initialized) return;
+        initialized = true;
+
+        try {
+            // Spark is available via SparkProvider in Paper 1.21+
+            spark = SparkProvider.get();
+            available = true;
+            LOGGER.info("Spark integration initialized successfully");
+        } catch (Exception e) {
+            LOGGER.log(Level.WARNING, "Spark not available, using fallback monitoring", e);
+            available = false;
+        }
+    }
+
+    /**
+     * Check if Spark is available and ready.
+     */
+    public static boolean isAvailable() {
+        return available && spark != null;
+    }
+
+    /**
+     * Get current profiling status.
+     * Returns a human-readable status string.
+     */
+    public static String getStatus() {
+        if (!isAvailable()) {
+            return "Spark not available";
+        }
+
+        try {
+            // Use reflection to check profiler status (API varies across versions)
+            boolean cpuRunning = isProfilerRunning("cpuProfiler");
+            boolean tickRunning = isProfilerRunning("tickProfiler");
+
+            if (cpuRunning) return "CPU profiler running";
+            if (tickRunning) return "Tick profiler running";
+            return "No active profiler";
+        } catch (Exception e) {
+            LOGGER.log(Level.WARNING, "Error checking Spark status", e);
+            return "Status check failed";
+        }
+    }
+
+    private static boolean isProfilerRunning(String methodName) {
+        try {
+            Method profilerMethod = spark.getClass().getMethod(methodName);
+            Object profiler = profilerMethod.invoke(spark);
+            if (profiler == null) return false;
+            Method isRunning = profiler.getClass().getMethod("isRunning");
+            return (boolean) isRunning.invoke(profiler);
+        } catch (Exception e) {
+            return false;
+        }
+    }
+
+    /**
+     * Start a CPU profiler for the specified duration.
+     *
+     * @param durationSeconds how long to profile (1-600 seconds)
+     * @return true if profiler started successfully
+     */
+    public static boolean startCpuProfile(int durationSeconds) {
+        if (!isAvailable()) return false;
+        if (durationSeconds < 1 || durationSeconds > 600) return false;
+
+        try {
+            Method profilerMethod = spark.getClass().getMethod("cpuProfiler");
+            Object profiler = profilerMethod.invoke(spark);
+            if (profiler == null) return false;
+            Method startMethod = profiler.getClass().getMethod("start");
+            CompletableFuture<Void> future = (CompletableFuture<Void>) startMethod.invoke(profiler);
+            LOGGER.info("Started CPU profiler for " + durationSeconds + " seconds");
+            scheduleStop(future, durationSeconds, "CPU");
+            return true;
+        } catch (Exception e) {
+            LOGGER.log(Level.WARNING, "Failed to start CPU profiler", e);
+            return false;
+        }
+    }
+
+    /**
+     * Start a tick profiler for the specified duration.
+     */
+    public static boolean startTickProfile(int durationSeconds) {
+        if (!isAvailable()) return false;
+        if (durationSeconds < 1 || durationSeconds > 600) return false;
+
+        try {
+            Method profilerMethod = spark.getClass().getMethod("tickProfiler");
+            Object profiler = profilerMethod.invoke(spark);
+            if (profiler == null) return false;
+            Method startMethod = profiler.getClass().getMethod("start");
+            CompletableFuture<Void> future = (CompletableFuture<Void>) startMethod.invoke(profiler);
+            LOGGER.info("Started tick profiler for " + durationSeconds + " seconds");
+            scheduleStop(future, durationSeconds, "Tick");
+            return true;
+        } catch (Exception e) {
+            LOGGER.log(Level.WARNING, "Failed to start tick profiler", e);
+            return false;
+        }
+    }
+
+    private static void scheduleStop(CompletableFuture<Void> future, int seconds, String type) {
+        future.completeOnTimeout(null, seconds, java.util.concurrent.TimeUnit.SECONDS);
+    }
+}
